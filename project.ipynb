{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pickle\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPool2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 148 images belonging to 2 classes.\n",
      "Found 148 images belonging to 2 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hasFlies': 0, 'noFlies': 1}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the location of training data\n",
    "path = 'C:/Users/jon/OneDrive/Documents/CSCE 5214/Project/dataset/training'\n",
    "\n",
    "# creating training and testing sets\n",
    "trainingData = ImageDataGenerator(shear_range = 0.1, zoom_range = 0.1, horizontal_flip = True)\n",
    "testingData = ImageDataGenerator()\n",
    "trainingSet = trainingData.flow_from_directory(path, target_size = (64, 64), batch_size = 32, class_mode = 'categorical')\n",
    "testingSet = testingData.flow_from_directory(path, target_size = (64, 64), batch_size = 32, class_mode = 'categorical')\n",
    "testingSet.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mappings {0: 'hasFlies', 1: 'noFlies'}\n",
      "\n",
      " The Number of output neurons:  2\n"
     ]
    }
   ],
   "source": [
    "# create a mapping between the classifications and the integer values representing the classifications\n",
    "trainingClasses = trainingSet.class_indices\n",
    "mapping={}\n",
    "\n",
    "for value, category in zip(trainingClasses.values(), trainingClasses.keys()):\n",
    "    mapping[value] = category\n",
    "\n",
    "# store mapping\n",
    "with open(\"mapping.pkl\", 'wb') as fileWriteStream:\n",
    "    pickle.dump(mapping, fileWriteStream)\n",
    "\n",
    "print(\"Mappings\", mapping)\n",
    "\n",
    "# set the number of outputs to the number of classifications\n",
    "outputLayer = len(mapping)\n",
    "print('\\n The Number of output neurons: ', outputLayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jon\\AppData\\Local\\Temp\\ipykernel_53072\\1042818116.py:12: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  classifier.fit_generator(trainingSet, steps_per_epoch = 4, epochs = 30, validation_data = testingSet, validation_steps = 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 161ms/step - loss: 150.1866 - accuracy: 0.4914 - val_loss: 11.7059 - val_accuracy: 0.6094\n",
      "Epoch 2/30\n",
      "4/4 [==============================] - 0s 136ms/step - loss: 5.1273 - accuracy: 0.5776 - val_loss: 1.1566 - val_accuracy: 0.4453\n",
      "Epoch 3/30\n",
      "4/4 [==============================] - 0s 119ms/step - loss: 1.3907 - accuracy: 0.5086 - val_loss: 1.7365 - val_accuracy: 0.3984\n",
      "Epoch 4/30\n",
      "4/4 [==============================] - 0s 129ms/step - loss: 1.1197 - accuracy: 0.5391 - val_loss: 0.9366 - val_accuracy: 0.6562\n",
      "Epoch 5/30\n",
      "4/4 [==============================] - 0s 130ms/step - loss: 0.6851 - accuracy: 0.6466 - val_loss: 0.7575 - val_accuracy: 0.5547\n",
      "Epoch 6/30\n",
      "4/4 [==============================] - 0s 119ms/step - loss: 0.7186 - accuracy: 0.6121 - val_loss: 0.7238 - val_accuracy: 0.5781\n",
      "Epoch 7/30\n",
      "4/4 [==============================] - 0s 131ms/step - loss: 0.7199 - accuracy: 0.6094 - val_loss: 0.6673 - val_accuracy: 0.6172\n",
      "Epoch 8/30\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.5820 - accuracy: 0.6641 - val_loss: 0.6433 - val_accuracy: 0.6719\n",
      "Epoch 9/30\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.5457 - accuracy: 0.6983 - val_loss: 0.5600 - val_accuracy: 0.6641\n",
      "Epoch 10/30\n",
      "4/4 [==============================] - 0s 133ms/step - loss: 0.5521 - accuracy: 0.6638 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
      "Epoch 11/30\n",
      "4/4 [==============================] - 0s 128ms/step - loss: 0.4856 - accuracy: 0.7759 - val_loss: 0.5118 - val_accuracy: 0.7656\n",
      "Epoch 12/30\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.4596 - accuracy: 0.7414 - val_loss: 0.4693 - val_accuracy: 0.7656\n",
      "Epoch 13/30\n",
      "4/4 [==============================] - 0s 130ms/step - loss: 0.4662 - accuracy: 0.7734 - val_loss: 0.4836 - val_accuracy: 0.7578\n",
      "Epoch 14/30\n",
      "4/4 [==============================] - 0s 129ms/step - loss: 0.4424 - accuracy: 0.7891 - val_loss: 0.4850 - val_accuracy: 0.7422\n",
      "Epoch 15/30\n",
      "4/4 [==============================] - 0s 118ms/step - loss: 0.4508 - accuracy: 0.7241 - val_loss: 0.4634 - val_accuracy: 0.7969\n",
      "Epoch 16/30\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.4961 - accuracy: 0.7586 - val_loss: 0.6180 - val_accuracy: 0.6875\n",
      "Epoch 17/30\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.5229 - accuracy: 0.7586 - val_loss: 0.4196 - val_accuracy: 0.7891\n",
      "Epoch 18/30\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.4837 - accuracy: 0.7672 - val_loss: 0.4939 - val_accuracy: 0.7422\n",
      "Epoch 19/30\n",
      "4/4 [==============================] - 0s 120ms/step - loss: 0.4568 - accuracy: 0.7586 - val_loss: 0.4202 - val_accuracy: 0.7812\n",
      "Epoch 20/30\n",
      "4/4 [==============================] - 0s 117ms/step - loss: 0.4066 - accuracy: 0.8017 - val_loss: 0.3573 - val_accuracy: 0.8438\n",
      "Epoch 21/30\n",
      "4/4 [==============================] - 0s 118ms/step - loss: 0.3743 - accuracy: 0.8276 - val_loss: 0.3200 - val_accuracy: 0.8594\n",
      "Epoch 22/30\n",
      "4/4 [==============================] - 0s 130ms/step - loss: 0.3664 - accuracy: 0.8362 - val_loss: 0.3274 - val_accuracy: 0.8594\n",
      "Epoch 23/30\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.3281 - accuracy: 0.8448 - val_loss: 0.3122 - val_accuracy: 0.8516\n",
      "Epoch 24/30\n",
      "4/4 [==============================] - 0s 120ms/step - loss: 0.2833 - accuracy: 0.8707 - val_loss: 0.3193 - val_accuracy: 0.8203\n",
      "Epoch 25/30\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.3230 - accuracy: 0.8534 - val_loss: 0.2849 - val_accuracy: 0.8672\n",
      "Epoch 26/30\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.3691 - accuracy: 0.8125 - val_loss: 0.2564 - val_accuracy: 0.8516\n",
      "Epoch 27/30\n",
      "4/4 [==============================] - 0s 133ms/step - loss: 0.3030 - accuracy: 0.8362 - val_loss: 0.2640 - val_accuracy: 0.8828\n",
      "Epoch 28/30\n",
      "4/4 [==============================] - 1s 134ms/step - loss: 0.2742 - accuracy: 0.8828 - val_loss: 0.2570 - val_accuracy: 0.8906\n",
      "Epoch 29/30\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.2604 - accuracy: 0.9052 - val_loss: 0.1933 - val_accuracy: 0.9297\n",
      "Epoch 30/30\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.2398 - accuracy: 0.8966 - val_loss: 0.1960 - val_accuracy: 0.9219\n",
      "###### Total Time Taken:  0 Minutes ######\n"
     ]
    }
   ],
   "source": [
    "# create neural network\n",
    "classifier = Sequential()\n",
    "classifier.add(Convolution2D(32, kernel_size = (5, 5), strides = (1, 1), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "classifier.add(MaxPool2D(pool_size = (2, 2)))\n",
    "classifier.add(Convolution2D(64, kernel_size = (5, 5), strides = (1, 1), activation = 'relu'))\n",
    "classifier.add(MaxPool2D(pool_size = (2, 2)))\n",
    "classifier.add(Flatten())\n",
    "classifier.add(Dense(64, activation = 'relu'))\n",
    "classifier.add(Dense(outputLayer, activation = 'softmax'))\n",
    "classifier.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = [\"accuracy\"])\n",
    "\n",
    "# see how long it takes\n",
    "start = time.time()\n",
    "classifier.fit_generator(trainingSet, steps_per_epoch = 4, epochs = 30, validation_data = testingSet, validation_steps = 4)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total Time Taken:\", round((end - start) / 60), 'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction is: hasFlies\n",
      "Prediction is: noFlies\n"
     ]
    }
   ],
   "source": [
    "# create testing for flies being present\n",
    "testingPath = 'C:/Users/jon/OneDrive/Documents/CSCE 5214/Project/dataset/testing/hasFlies/housefly-2266095__340.jpg'\n",
    "test_image = image.load_img(testingPath, target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "\n",
    "result = classifier.predict(test_image, verbose = 0)\n",
    "\n",
    "print('Prediction is:', mapping[np.argmax(result)])\n",
    "\n",
    "# create testing for flies not being present\n",
    "testingPath = 'C:/Users/jon/OneDrive/Documents/CSCE 5214/Project/dataset/testing/noFlies/mosquito-719613__340.jpg'\n",
    "test_image = image.load_img(testingPath, target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "\n",
    "result = classifier.predict(test_image, verbose = 0)\n",
    "\n",
    "print('Prediction is:', mapping[np.argmax(result)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad96bdf6f7a08fd3a072c01502de9dfd906416659585d4612df6fe881305fd2d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
